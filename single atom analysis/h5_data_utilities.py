"""
some functions that streamline working with h5 files generated by ARTIQ experiments
as well as some functions for plotting
"""

import numpy as np
import os
import h5py
import matplotlib as mpl
from matplotlib import pyplot as plt

results = "C:\\Networking Experiment\\artiq codes\\artiq-master\\results\\"

MHz = 1e6
kHz = 1e3
ms = 1e-3
us = 1e-6
V = 1

def eval_str_from_h5(h5_str):
    """a stupid way to evaluate python evaluable strings I saved as ARTIQ datasets"""
    return eval(str(np.array(h5_str))[2:-1])

def str_from_h5(h5_str):
    """a stupid way to read strings I saved as ARTIQ datasets"""
    return str(np.array(h5_str))[2:-1]

def get_files_by_criteria(date_filters,name_filters,condition,start_dir=results,include_path=True,print_filenames=False):
    file_list = []
    for root, dirs, files in os.walk(start_dir,topdown=False):
        for name in files:
            if True in set([x in root for x in date_filters]):
                name_filter_set = set([x in name for x in name_filters])
                if len(name_filter_set) == 1 and True in name_filter_set:
                    filename = os.path.join(root, name)
                    try:
                        h5py.File(filename)
                        if condition(filename):
                            if not include_path:
                                filename = name
                                if print_filenames:
                                    print(filename)
                            file_list.append(filename)
                    except OSError:
                        print(f"skipping {filename}, which is corrupt")
    return file_list

def h5_archive_and_datasets_to_locals(f, parent_locals, quiet=False):
    """
    Adds the values in archive and datasets fields of an h5 file to your current scope's local variables

    This allows for using the h5's data by name in your code without any additional ceremony.

    Arguments:
        f: the h5 file object
        parent_locals: set this equal to locals() in your code
        quiet: False by default, will print out any fields that failed to be cast to python types. 
            if True, these messages will not be printed.
    Returns:
        nothing is returned
    """
    for data_level in ['archive','datasets']:
        for key in f[data_level].keys():
            try:
                shape = f[data_level][key].shape
                dtype = f[data_level][key].dtype
                raw_value = f[data_level][key][()]
                if shape == (): # scalar
                    if dtype == object:
                        if type(raw_value) == bytes:
                            
                            try:
                                value = str_from_h5(f[data_level][key])
                            except:
                                raise
                        else:
                            try:
                                eval(f[data_level][key][()])
                            except:
                                raise
                    else:
                        value = f[data_level][key][()]
                    # print(key, shape, dtype, value)
                    # locals().update({key: value})
                else:
                    # print(key, shape, dtype, value)
                    value = f[data_level][key][:]
                    # locals().update({key: value})

                if key == 'photocounts' or key == 'photocounts2':
                    value = value[1:]
                
                parent_locals.update({key: value})
            except:
                if not quiet:
                    print("oops in:",data_level, key, shape, dtype, value)

def print_h5_archive_and_datasets(f, scalars_only=True, quiet=False):
    """
    Adds the values in archive and datasets fields of an h5 file to your current scope's local variables

    This allows for using the h5's data by name in your code without any additional ceremony.

    Arguments:
        f: the h5 file object
        parent_locals: set this equal to locals() in your code
        quiet: False by default, will print out any fields that failed to be cast to python types. 
            if True, these messages will not be printed.
    Returns:
        nothing is returned
    """
    for data_level in ['archive','datasets']:
        for key in f[data_level].keys():
            try:
                shape = f[data_level][key].shape
                dtype = f[data_level][key].dtype
                raw_value = f[data_level][key][()]
                if shape == (): # scalar
                    if dtype == object:
                        if type(raw_value) == bytes:
                            
                            try:
                                value = str_from_h5(f[data_level][key])
                            except:
                                raise
                        else:
                            try:
                                eval(f[data_level][key][()])
                            except:
                                raise
                    else:
                        value = f[data_level][key][()]
                    # print(key, shape, dtype, value)
                    # locals().update({key: value})
                else:
                    # print(key, shape, dtype, value)
                    value = f[data_level][key][:]
                    # locals().update({key: value})

                if key == 'photocounts' or key == 'photocounts2':
                    value = value[1:]

                if scalars_only:
                    try:
                        len(value)
                    except:
                        print(f"{key} = {value}")
                else:
                    print(f"{key} = {value}")
            except:
                if not quiet:
                    print("oops in:",data_level, key, shape, dtype, value)

def get_loading_and_retention(photocounts,photocounts2,measurements,iterations,cutoff1,cutoff2=None):
        """
        Returns retention, loading rate, and number of atoms loaded for each experiment iteration.
        
        cutoff1 and cutoff2 (optional) are the atom loading thresholds in units counts.
        """
        
        if cutoff2 is None:
            cutoff2 == cutoff1
        
        retention_array = np.zeros(iterations)
        loading_rate_array = np.zeros(iterations)
        n_atoms_loaded_array = np.zeros(iterations)
                
        for i in range(iterations):
            shot1 = photocounts[i*measurements:(i+1)*measurements]
            shot2 = photocounts2[i*measurements:(i+1)*measurements]
            
            atoms_loaded = [x > cutoff1 for x in shot1]
            n_atoms_loaded = sum(atoms_loaded)
            atoms_retained = [x > cutoff2 and y for x,y in zip(shot2, atoms_loaded)]
            retention_fraction = 0 if not n_atoms_loaded > 0 else sum(atoms_retained)/sum(atoms_loaded)
            loading_rate_array[i] = n_atoms_loaded/measurements
            n_atoms_loaded_array[i] = n_atoms_loaded
            retention_array[i] = retention_fraction
        return retention_array, loading_rate_array, n_atoms_loaded_array


# def plot_retention_and_histograms(experiment_name, photocounts, photocounts2, cutoff1,cutoff2,n_measurements, scan_variable1_name, scan_variable2_name, scan_sequence1,scan_sequence2, showloading=False, showhist=True):
#     """
#     Plot retention and readout histogram(s) for a GeneralVariableScan
#     """

#     iterations = len(scan_sequence1)*len(scan_sequence2)
    
#     if scan_variable2_name != '':
#         scan_is_2D = True
#     else:
#         scan_sequence2 = np.zeros(1)
#         scan_is_2D = False

#     retention_array = np.zeros(iterations)
#     loading_rate_array = np.zeros(iterations)
#     n_atoms_loaded_array = np.zeros(iterations)
#     shape = (len(scan_sequence2),len(scan_sequence1))
#     loading_rate_raveled = np.reshape(loading_rate_array,shape,order='F') # rows have constant variable2
#     n_atoms_loaded_raveled = np.reshape(n_atoms_loaded_array,shape,order='F') # rows have constant variable2
#     retention_raveled = np.reshape(retention_array,shape,order='F') # rows have constant variable2
    
#     ncols = len(scan_sequence2)
#     nrows = len(scan_sequence1)
    
#     dvar1 = abs(scan_sequence1[1]-scan_sequence1[0])
#     if scan_is_2D:
#         dvar2 = abs(scan_sequence2[1]-scan_sequence2[0])

#     if showhist:
#         fig,axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(10,7))
#         for i, ax in enumerate(axes.flat):
#             shot1 = photocounts[i*n_measurements:(i+1)*n_measurements]
#             shot2 = photocounts2[i*n_measurements:(i+1)*n_measurements]
#             ax.hist(shot1,bins=30, facecolor=(0.0, 0.5, 1, 1),label='shot 1')
#             ax.hist(shot2,bins=30, facecolor=(1.0, 0.0, 0.0, 0.1),label='shot 2', edgecolor=(0, 0, 0, 1), linestyle='-')
#             ax.set_title(f"retention={retention_array[i]:.2f}\nloading rate={loading_rate_array[i]:.2f}",fontsize=8)
#             # ax.set_ylabel("occurences")
#             # ax.set_xlabel("photons")
#             ax.set_xticks([])
#             ax.set_yticks([])
#         if scan_is_2D: # todo
#             axes.flat[ncols-1].legend(loc=(1.05,-nrows/2))
#             [axes[-1,ncols-i-1].set_xlabel(var2) for i,var2 in enumerate(scan_sequence2)]
#             [axes[nrows-i-1,0].set_ylabel(var1,rotation=0) for i,var1 in enumerate(scan_sequence1)]
#             [axes[nrows-i-1,0].yaxis.set_label_coords(-0.2,0.4) for i in range(nrows)]
#         fig.text(0.45,-0.5, scan_variable2_name)
#         fig.text(0.05,0.35, scan_variable1_name,rotation=90)
#         plt.subplots_adjust(bottom=-0.4)
#         plt.show()
    
#     if scan_is_2D:
#         # plot a colormap of the retention
#         fig,ax = plt.subplots()
#         cax=ax.imshow(retention_raveled,cmap='afmhot',interpolation='none',
#                       extent=[scan_sequence1[0]-dvar1/2,scan_sequence1[-1]+dvar1/2,scan_sequence2[-1]+dvar2/2,scan_sequence2[0]-dvar2/2])
#         im = ax.get_images()
#         extent =  im[0].get_extent()
#         # plt.setp(ax.spines.values(), linewidth=0.1)
#         ax.set_aspect(abs((extent[1]-extent[0])/(extent[3]-extent[2])))
#         ax.set_xticks(scan_sequence1)
#         ax.set_yticks(scan_sequence2_name)
#         ax.set_title(experiment_name_name)
#         ax.set_xlabel(scan_variable1_name)
#         ax.set_ylabel(scan_variable2_name)
#         # ax.tick_params(axis='both', labelsize=10)
#         fig.colorbar(cax)
#         # plt.clim(0,1)
#         plt.show()

#     # plot a retention curve vs variable 1 for each variable 2 value
#     cmap = mpl.colormaps['inferno']
#     for i, retention, n_loaded, var2 in zip(range(len(scan_sequence2)),retention_raveled, n_atoms_loaded_raveled, scan_sequence2):
#         plt.plot(scan_sequence1, retention,color=cmap(i/len(scan_sequence2)),linestyle='--')
#         plt.scatter(scan_sequence1, retention,color=cmap(i/len(scan_sequence2)),label=scan_variable2_name+"="+str(var2))
#         errs = [1/np.sqrt(n) if n > 0 else np.inf for n in n_loaded]
#         plt.errorbar(scan_sequence1, retention, errs, ls='none',color=cmap(i/len(scan_sequence2)))
#         plt.ylim((0,1))
#         plt.xlabel(scan_variable1_name)
#         plt.ylabel("retention")
#         plt.legend()
#         plt.title(experiment_name)
#         plt.show()
    
#     if showloading:
#         for i, loading, n_loaded, var2 in zip(range(len(scan_sequence2)),loading_rate_raveled, n_atoms_loaded_raveled, scan_sequence2):
#             plt.plot(scan_sequence1, loading,color=cmap(i/len(scan_sequence2)),linestyle='--')
#             plt.scatter(scan_sequence1, loading,color=cmap(i/len(scan_sequence2)),label=scan_variable2_name+"="+str(var2))
#             errs = [1/np.sqrt(n) if n > 0 else np.inf for n in n_loaded]
#             plt.errorbar(scan_sequence1, loading, errs, ls='none',color=cmap(i/len(scan_sequence2)))
#             plt.ylim((0,1))
#             plt.xlabel(scan_variable1_name)
#             plt.ylabel("loading rate")
#             plt.legend()
#             plt.title(experiment_name)
#             plt.show()